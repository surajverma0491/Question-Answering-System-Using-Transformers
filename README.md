# â“ Question Answering System Using Transformers

A powerful and efficient Question Answering (QA) system built using the **ALBERT-base-v2** transformer model. It leverages Hugging Face's `transformers` and `datasets` libraries, fine-tuned on the **SQuAD 2.0** dataset to answer questions given a context passage.

---

## ðŸš€ Features

- ðŸ§  Fine-tuned ALBERT model for extractive question answering
- ðŸ“š Trained on SQuAD 2.0 (Stanford Question Answering Dataset)
- âœ… Supports "no answer" questions as well
- ðŸ§ª Evaluated with EM (Exact Match) and F1 metrics
- ðŸ“Ž Easily test the model with custom context and questions

---

## ðŸ› ï¸ Tech Stack

- Python 3.11
- Hugging Face Transformers
- Datasets (`squad`)
- PyTorch
- Google Colab (GPU T4 - free tier)

---

## ðŸ§‘â€ðŸ« Model Architecture

The model used is:

> `albert-base-v2` â€“ A Lite BERT optimized for performance and low memory usage, ideal for Colab environments.

---

## ðŸ“Š Evaluation Metrics

- **Exact Match (EM)** â€“ Measures how many predictions match the ground truth exactly.
- **F1 Score** â€“ Harmonic mean of precision and recall between predicted and actual answers.

Example output:
```text
Exact Match (EM): 74.12
F1 Score: 80.37
